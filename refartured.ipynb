{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:42:12.900443Z",
     "start_time": "2019-04-24T18:41:54.233593Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import TensorBoard\n",
    "from sklearn.model_selection import train_test_split as tts\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psutil\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:42:12.913440Z",
     "start_time": "2019-04-24T18:42:12.907442Z"
    }
   },
   "outputs": [],
   "source": [
    "def getMinData(dir):\n",
    "    minValue = 9999999\n",
    "    for file in os.listdir(dir):\n",
    "        fileValue = np.load(dir + file).shape[0]\n",
    "        if minValue > fileValue:\n",
    "            minValue = fileValue\n",
    "    return minValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defining global variabals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:44:03.963520Z",
     "start_time": "2019-04-24T18:42:12.924437Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# All images are 28 * 28 * 1 = 784\n",
    "# 1 because images are grey scalded images\n",
    "IMAGE_ROWS = 28\n",
    "IMAGE_COLS = 28\n",
    "IMAGE_SIZE = IMAGE_ROWS * IMAGE_ROWS\n",
    "\n",
    "# Path to data\n",
    "IMAGE_DIR = \"./data/\"\n",
    "\n",
    "# Total number of numpy file\n",
    "NUM_IMAGES = len(glob.glob1(IMAGE_DIR, \"*.npy\"))\n",
    "\n",
    "# How many element in each image\n",
    "TOTAL_ELEMENTS_PER_IMAGE = 500\n",
    "\n",
    "MAX_NUM_ELEMENTS = getMinData(IMAGE_DIR)\n",
    "\n",
    "NUM_ITERATON = MAX_NUM_ELEMENTS // TOTAL_ELEMENTS_PER_IMAGE\n",
    "\n",
    "BATCH_SIZE = 512\n",
    "IMAGE_SHAPE = (IMAGE_ROWS, IMAGE_COLS, 1)\n",
    "\n",
    "# setting for all labels a unique value\n",
    "label_map = {}\n",
    "\n",
    "for i, file in enumerate(os.listdir(IMAGE_DIR)):\n",
    "    label_map[file[:-4]] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the Model\n",
    "## Defining the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:44:04.328404Z",
     "start_time": "2019-04-24T18:44:03.970519Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 11, 11, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 9, 9, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 9, 9, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 7, 7, 256)         295168    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 7, 7, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 5, 5, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 5, 5, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 345)               4416345   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 345)               119370    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 345)               119370    \n",
      "=================================================================\n",
      "Total params: 6,223,085\n",
      "Trainable params: 6,223,085\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=32, kernel_size=3,\n",
    "                 activation=\"relu\", input_shape=IMAGE_SHAPE))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Conv2D(filters=64, kernel_size=3,\n",
    "                 activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(filters=128, kernel_size=3,\n",
    "                 activation=\"relu\"))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Conv2D(filters=256, kernel_size=3,\n",
    "                 activation=\"relu\"))\n",
    "model.add(Dropout(0.35))\n",
    "model.add(Conv2D(filters=512, kernel_size=3,\n",
    "                 activation=\"relu\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(NUM_IMAGES, activation=\"relu\"))\n",
    "model.add(Dense(NUM_IMAGES, activation=\"relu\"))\n",
    "model.add(Dense(NUM_IMAGES, activation=\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-24T18:44:04.395383Z",
     "start_time": "2019-04-24T18:44:04.337402Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-29T20:47:30.726834Z",
     "start_time": "2019-04-24T18:44:04.404381Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0, NUM_ITERATON):\n",
    "    print(\"{} of {}\".format(i, NUM_ITERATON))\n",
    "    minBound = i * TOTAL_ELEMENTS_PER_IMAGE\n",
    "    maxBound = minBound + TOTAL_ELEMENTS_PER_IMAGE\n",
    "\n",
    "    x_train = np.ndarray(shape=(0, 784), dtype=np.float32)\n",
    "    y_train = np.array([], dtype=np.uint16)\n",
    "\n",
    "    for file in os.listdir(IMAGE_DIR):\n",
    "        elements = np.load(IMAGE_DIR + file)[minBound:maxBound] / 255\n",
    "        x_train = np.concatenate((x_train, elements))\n",
    "        labels = np.full(elements.shape[0], label_map[file[:-4]])\n",
    "        y_train = np.append(y_train, labels)\n",
    "\n",
    "    # Spliting the loaded data into testing and validating\n",
    "    x_train, x_validate, y_train, y_validate = tts(x_train, y_train, test_size=.2)\n",
    "\n",
    "    # Reshape the data\n",
    "\n",
    "    x_train = x_train.reshape(x_train.shape[0], *IMAGE_SHAPE)\n",
    "    x_validate = x_validate.reshape(x_validate.shape[0], *IMAGE_SHAPE)\n",
    "\n",
    "    # Fiting the model\n",
    "\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=128, verbose=1,\n",
    "              validation_data=(x_validate, y_validate))\n",
    "\n",
    "    # Saving the model after every fit\n",
    "    model.save('model_first.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "469px",
    "left": "1232px",
    "right": "20px",
    "top": "112px",
    "width": "352px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
